{"cells":[{"cell_type":"code","source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6-cgy6_LWNw","executionInfo":{"status":"ok","timestamp":1671106899713,"user_tz":-60,"elapsed":1762,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"314a083b-d36c-4fe1-a481-d6c0e267c822"},"id":"-6-cgy6_LWNw","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Thu Dec 15 12:21:38 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   61C    P0    27W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s11O2odbLXpm","executionInfo":{"status":"ok","timestamp":1671106899713,"user_tz":-60,"elapsed":16,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"5a4a8b13-aa77-4e94-80f1-c5cb3ae0c0a6"},"id":"s11O2odbLXpm","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}]},{"cell_type":"code","source":["!pip install cellpose  #Put in such lines comment if you're running on notebook!! easier for me later on"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zANzsROdLMrf","executionInfo":{"status":"ok","timestamp":1671106909274,"user_tz":-60,"elapsed":9569,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"b20d95a1-6b89-4ef7-bec2-7c0a5ab90554"},"id":"zANzsROdLMrf","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting cellpose\n","  Downloading cellpose-2.1.1-py3-none-any.whl (171 kB)\n","\u001b[K     |████████████████████████████████| 171 kB 28.0 MB/s \n","\u001b[?25hRequirement already satisfied: numba>=0.53.0 in /usr/local/lib/python3.8/dist-packages (from cellpose) (0.56.4)\n","Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.8/dist-packages (from cellpose) (1.13.0+cu116)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from cellpose) (4.64.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.8/dist-packages (from cellpose) (5.5.0)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.8/dist-packages (from cellpose) (2022.10.10)\n","Collecting fastremap\n","  Downloading fastremap-1.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 53.7 MB/s \n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from cellpose) (4.6.0.66)\n","Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from cellpose) (1.21.6)\n","Requirement already satisfied: llvmlite in /usr/local/lib/python3.8/dist-packages (from cellpose) (0.39.1)\n","Collecting imagecodecs\n","  Downloading imagecodecs-2022.9.26-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.1 MB)\n","\u001b[K     |████████████████████████████████| 35.1 MB 335 kB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from cellpose) (1.7.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba>=0.53.0->cellpose) (4.13.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.53.0->cellpose) (57.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.6->cellpose) (4.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba>=0.53.0->cellpose) (3.11.0)\n","Installing collected packages: imagecodecs, fastremap, cellpose\n","Successfully installed cellpose-2.1.1 fastremap-1.13.3 imagecodecs-2022.9.26\n"]}]},{"cell_type":"code","source":["!pip install scikit-image==0.19.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTyYduGzm4iR","executionInfo":{"status":"ok","timestamp":1671106916736,"user_tz":-60,"elapsed":7479,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"c5b63c9a-40b2-4ee6-9825-4f4480c4fa40"},"id":"dTyYduGzm4iR","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-image==0.19.3\n","  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n","\u001b[K     |████████████████████████████████| 14.0 MB 32.7 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (1.21.6)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (2.8.8)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (2022.10.10)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (7.1.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (21.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (1.7.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image==0.19.3) (2.9.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->scikit-image==0.19.3) (3.0.9)\n","Installing collected packages: scikit-image\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.18.3\n","    Uninstalling scikit-image-0.18.3:\n","      Successfully uninstalled scikit-image-0.18.3\n","Successfully installed scikit-image-0.19.3\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c666sHiOLP0r","executionInfo":{"status":"ok","timestamp":1671106944691,"user_tz":-60,"elapsed":27970,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"9d1e13e1-fe3e-46c6-9779-36809df23055"},"id":"c666sHiOLP0r","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","execution_count":6,"id":"7880d81b-28e4-4e28-9d81-bb5833bd69c3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7880d81b-28e4-4e28-9d81-bb5833bd69c3","executionInfo":{"status":"ok","timestamp":1671106955817,"user_tz":-60,"elapsed":11146,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"3b64ab0c-97d9-4a45-b22c-2db38de4a25b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 8.1.2. Several security issues (CVE-2021-27921, CVE-2021-25290, CVE-2021-25291, CVE-2021-25293, and more) have been fixed in pillow 8.1.2 or higher. We recommend to upgrade this library.\n","  from .collection import imread_collection_wrapper\n"]}],"source":["# Import modules\n","import numpy as np\n","import time, os, sys, random\n","from urllib.parse import urlparse\n","import skimage.io\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from cellpose import models\n","from cellpose.io import imread\n","from cellpose import plot\n","from skimage.util import img_as_ubyte\n","import pandas as pd\n","from skimage.measure import label, regionprops\n","from skimage.measure import label, regionprops\n","from skimage import measure"]},{"cell_type":"code","execution_count":7,"id":"3dd976f8-c328-411d-860b-995d6c65feb1","metadata":{"id":"3dd976f8-c328-411d-860b-995d6c65feb1","executionInfo":{"status":"ok","timestamp":1671106955823,"user_tz":-60,"elapsed":40,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["import scipy\n","from scipy import ndimage as ndi\n","import cv2\n","from skimage.morphology import square, dilation\n","from sklearn.cluster import KMeans, DBSCAN\n","# https://stackoverflow.com/questions/19970764/making-feature-vector-from-gabor-filters-for-classification\n","# https://stackoverflow.com/questions/20608458/gabor-feature-extraction"]},{"cell_type":"markdown","id":"9db57d46-5502-4c69-b3e5-77ed104caf32","metadata":{"id":"9db57d46-5502-4c69-b3e5-77ed104caf32"},"source":["# Image segmentation"]},{"cell_type":"code","source":["nb_images = 12\n","\n","alphabet = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n","\n","def end_of_file_name(letter,number_tf,number_img,Type):\n","  \"\"\"\n","  letter : 'A' to 'H'\n","  number : 1 to 12\n","  type = 'TexasRed' or 'YFP'\n","  \"\"\"\n","  return(letter+' - '+str(number_tf)+'(fld '+str(number_img)+' wv '+Type+' - '+Type+').tif')\n","\n","Image_Directory = \"/content/gdrive/MyDrive/ML_2_transcripted_cherry/TF1/\""],"metadata":{"id":"FSDZOvGULe-o","executionInfo":{"status":"ok","timestamp":1671106955824,"user_tz":-60,"elapsed":36,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"id":"FSDZOvGULe-o","execution_count":8,"outputs":[]},{"cell_type":"markdown","id":"c2cdd4de-9da7-4418-a714-258c71e9e1cd","metadata":{"id":"c2cdd4de-9da7-4418-a714-258c71e9e1cd"},"source":["***\n","# Feature extraction"]},{"cell_type":"code","execution_count":11,"id":"1465a7ed-0db3-4384-9abc-dfa8208579d9","metadata":{"id":"1465a7ed-0db3-4384-9abc-dfa8208579d9","executionInfo":{"status":"ok","timestamp":1671106955826,"user_tz":-60,"elapsed":28,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["def gabor_feature_extraction(kernels,patch_data):\n","    # Apply Gabor filter: We receive per kernel a response. We stack all the response to one matrix---------------------------------------------------------\n","    image = patch_data\n","    g_response = []\n","\n","    for k, kernel in enumerate(kernels):\n","        filtered = ndi.convolve(image, kernel, mode='wrap')\n","        g_response.append(filtered)\n","    n_clusters = len(g_response)\n","    g_response = np.vstack(g_response)\n","\n","    # Cluster Gabor response with k-means. Find which part of the pixel belongs to which Gabor response ---------------------------------------------------------\n","    random_state = 1\n","    random.seed(random_state)\n","    kmean = KMeans(n_clusters, random_state=random_state).fit(g_response) #\n","\n","    # Texton map: Assign each pixel to the identity of the closest cluster center---------------------------------------------------------\n","    histogram = np.histogram(kmean.labels_, bins = len(np.unique(kmean.labels_)))\n","    # Normalize\n","    gabor_feature = histogram[0] / histogram[0].sum()\n","    return gabor_feature"]},{"cell_type":"code","execution_count":12,"id":"c360298d-69df-4362-b7f3-dc2c2fe04476","metadata":{"id":"c360298d-69df-4362-b7f3-dc2c2fe04476","executionInfo":{"status":"ok","timestamp":1671106955828,"user_tz":-60,"elapsed":26,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["def feature_binary_pattern(patch_data):\n","    # Apply lbp\n","    METHOD = 'uniform' #  'default'\n","    radius = 1\n","    n_points = 8 * radius\n","    lbp = local_binary_pattern(patch_data, n_points, radius, METHOD)\n","    \n","    # Create histogram\n","    count = len(np.unique(lbp))\n","    H, bins = np.histogram(lbp, count)\n","\n","    # Drop background values\n","    w = width = radius - 1\n","    index_background = n_points - w\n","    H = H[0: index_background]\n","    bins =  bins[0: index_background]\n","\n","    # plt.bar(bins,H,width=1)\n","    \n","    # Normalize\n","    lbp_feature = H / H.sum()\n","    return lbp_feature"]},{"cell_type":"code","execution_count":13,"id":"d5d82b60-812a-40a1-94c0-d2211ee97863","metadata":{"id":"d5d82b60-812a-40a1-94c0-d2211ee97863","executionInfo":{"status":"ok","timestamp":1671106955828,"user_tz":-60,"elapsed":25,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["from skimage.feature import local_binary_pattern\n","from skimage.color import label2rgb\n","from skimage.transform import rotate"]},{"cell_type":"code","execution_count":14,"id":"8c0dc673-770f-4a72-bcb5-a12ff16f3383","metadata":{"id":"8c0dc673-770f-4a72-bcb5-a12ff16f3383","executionInfo":{"status":"ok","timestamp":1671106955829,"user_tz":-60,"elapsed":24,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["# Initialize list of features \n","columnname = [\"\" for i in range(1)]\n","patch_size = [0 for i in range(1)]\n","mean_intensity = [0 for i in range(1)]\n","sum_intensity = [0 for i in range(1)]\n","median_intensity = [0 for i in range(1)]\n","variance_intensity = [0 for i in range(1)]\n","imgs = [-1 for i in range(1)]"]},{"cell_type":"code","execution_count":15,"id":"7e8dcc4c-814f-40a5-94d2-cb78fa415d55","metadata":{"id":"7e8dcc4c-814f-40a5-94d2-cb78fa415d55","executionInfo":{"status":"ok","timestamp":1671106955830,"user_tz":-60,"elapsed":24,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["# prepare Gabor filter bank kernels---------------------------------------------------------\n","kernels = []\n","sigmas = [1,3]\n","tilts = [0,0.25,0.5,0.75] # perpendicular, diagonal, horizontal, other diagonal \n","Wavelengths = [0.25,0.75] \n","gamma =  0.5 # Spatial aspect ratio\n","psi = 0 # Phase offset.\n","\n","for tilt in tilts:\n","    for sigma in sigmas:\n","        for lambd in Wavelengths:\n","            kernel = cv2.getGaborKernel((10,10), sigma, tilt, lambd, gamma, psi, ktype = cv2.CV_32F)\n","            kernels.append(kernel)"]},{"cell_type":"code","execution_count":16,"id":"2af4b125-5c04-4fe7-9bf7-383e7672b423","metadata":{"id":"2af4b125-5c04-4fe7-9bf7-383e7672b423","executionInfo":{"status":"ok","timestamp":1671106955830,"user_tz":-60,"elapsed":23,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"outputs":[],"source":["from skimage.feature import local_binary_pattern"]},{"cell_type":"code","source":["#Automatization ! \n","\n","Image_Directory = \"/content/gdrive/MyDrive/ML_2_transcripted_cherry/TF1/\"\n","cherry_condition = \"TexasRed\"\n","ypet_condition = \"YFP\"\n","\n","channels = [0,0] # Corresponds to greyscale image\n","diameter = None # Model was trained on diameters of 17 pixels. None-> automated estimation of the diameter. Can be changed by hand later\n","flow_threshold = 0.4 # maximum allowed error of the flows for each mask, default = 0.4\n","gpu = True\n","model_type='nuclei'\n","\n","# Set model\n","model = models.Cellpose(gpu, model_type)\n","\n","let = 'C' #letter of the TF file to be analyzed, could also be automatized\n","\n","for k in np.arange(0,12):\n","  Cherry_file = [Image_Directory+end_of_file_name(let,k+1,i+1,cherry_condition) for i in range(12)]\n","  Ypet_file = [Image_Directory+end_of_file_name(let,k+1,i+1,ypet_condition) for i in range(12)]\n","\n","  # Initialize lists containing cherry, ypet images\n","  cherry_imgs = np.ndarray(nb_images,dtype = np.ndarray)\n","  ypet_imgs = np.ndarray(nb_images,dtype = np.ndarray)\n","\n","  # Read image (We donnot add it in for loop above to enable reading subset of image)\n","  ii = 0\n","  jj = 0\n","  for i in range(12): #For loop to avoid trying to read images that does not exist\n","      #print(Cherry_file[ii])\n","      if (os.path.isfile(Cherry_file[ii])):\n","        cherry_imgs[ii] = imread(Cherry_file[ii])\n","        ii = ii+1\n","      if (os.path.isfile(Ypet_file[jj])):\n","        ypet_imgs[jj] = imread(Ypet_file[jj])\n","        jj=jj+1\n","      \n","  cherry_imgs = cherry_imgs.tolist()\n","  ypet_imgs = ypet_imgs.tolist()\n","\n","  cherry_imgs = cherry_imgs[0:ii]\n","  ypet_imgs = ypet_imgs[0:jj]\n","  #print('ii is ',ii)\n","  #print(jj)\n","  # Nuclei segmentation of all images within cherry_imgs list\n","  masks, flows, styles, diams = model.eval(cherry_imgs, diameter=diameter, channels=channels, flow_threshold=flow_threshold, do_3D=False)\n","\n","  imgs = [-1 for i in range(1)]\n","  range_s = 1 #Just to initialize the Ypet_glob\n","  columnname = [\"\" for i in range(1)]\n","  blur = [False for i in range(1)]\n","  patch_size = [0 for i in range(1)]\n","  mean_intensity = [0 for i in range(1)]\n","  sum_intensity = [0 for i in range(1)]\n","  median_intensity = [0 for i in range(1)]\n","  std_intensity = [0 for i in range(1)]\n","  var_intensity = [0 for i in range(1)]\n","  skew_intesity = [0 for i in range(1)]\n","  kurt_intesity = [0 for i in range(1)]\n","  iqr_intesity = [0 for i in range(1)]\n","  entropy_intesity = [0 for i in range(1)]\n","  gabor_features = [0 for i in range(1)]\n","  lbp_features = [0 for i in range(1)]\n","  blur_lapl = [False for i in range(1)]\n","  blur_ski = [False for i in range(1)]\n","  TF_name = ['None']\n","  ypet_intensity_glob = pd.DataFrame(index=columnname)\n","  ypet_intensity_glob['img'] = imgs\n","  ypet_intensity_glob['fld'] = ypet_intensity_glob['img']+1 #To remember the flow from which (img+1)\n","  ypet_intensity_glob['TF_name'] = TF_name\n","  ypet_intensity_glob['blur_lapl'] = blur_lapl\n","  ypet_intensity_glob['blur_ski'] = blur_ski\n","  ypet_intensity_glob['patch_size'] = patch_size\n","  ypet_intensity_glob['mean_intensity'] = mean_intensity\n","  ypet_intensity_glob['sum_intensity'] = sum_intensity\n","  ypet_intensity_glob['median_intensity'] = median_intensity\n","  ypet_intensity_glob['standard_deviation'] = std_intensity \n","  ypet_intensity_glob['variance'] = var_intensity\n","  ypet_intensity_glob['skewness'] = skew_intesity\n","  ypet_intensity_glob['kurtosis'] = kurt_intesity\n","  ypet_intensity_glob['interquartile_range ']= iqr_intesity\n","  ypet_intensity_glob['entropy'] = entropy_intesity\n","\n","      \n","  for j in range(min(ii,jj)):\n","    # Initialize features: Faster then appending values to list with append\n","    mask =  masks[j]  \n","    TF_name = let+' - '+str(k+1)  #TF_name_tot[j]\n","    start_nucleus = 1 # we have to at least start from 1, otherwise we take whole mask\n","    end_nucleus =  len(np.unique(mask)) # len(np.unique(mask))  #IMAGE SPECIFIC: cases where cell are big enough (sell last cell of the notebook)\n","    range_s = range(start_nucleus, end_nucleus)\n","    imgs = [j for i in range_s]\n","    ypet = ypet_imgs[j]\n","    columnname = [\"\" for i in range_s]\n","    blur = [False for i in range_s]\n","    patch_size = [0 for i in range_s]\n","    mean_intensity = [0 for i in range_s]\n","    sum_intensity = [0 for i in range_s]\n","    median_intensity = [0 for i in range_s]\n","    std_intensity = [0 for i in range_s]\n","    var_intensity = [0 for i in range_s]\n","    skew_intesity = [0 for i in range_s]\n","    kurt_intesity = [0 for i in range_s]\n","    iqr_intesity = [0 for i in range_s]\n","    entropy_intesity = [0 for i in range_s]\n","    gabor_features = [0 for i in range_s]\n","    lbp_features = [0 for i in range_s]\n","    blur_lapl = [False for i in range_s]\n","    blur_ski = [False for i in range_s]\n","                  \n","    #calculate different properties of the mask\n","    props = regionprops(mask)\n","    \n","    #initialize arrays to store information from the mask\n","    perimeter = [0 for i in range_s]\n","    feret_diameter_max = [0 for i in range_s]\n","    area_test = [0 for i in range_s]\n","    axis_major = [0 for i in range_s]\n","    axis_minor = [0 for i in range_s]\n","    solidity = [0 for i in range_s]\n","\n","    '''\n","    # Iterate to explore and find good threshold in exploration phase\n","    patch_data_list = []\n","    variance_data_list = []'''\n","    # Threshold for blur detection\n","    var_threshold = 10000000\n","    blur_threshold = 0.7\n","    \n","    # Iterate through all nucleus: Take submatrix, Calculate patch size and corresponding ypet signal (mean) and store it into ypet_intensity\n","    iter_i = 0 # Ensures that no 0 are saved where patch is too small/big\n","    \n","    for i in range_s:# # Iterate through all nucleus: in range(start_nucleus, end_nucleus)\n","        cur = ypet[mask==i]\n","        patch_size_ = np.count_nonzero(~np.isnan(cur))\n","        \n","        # Extract subimage ----------------------------------------------------------------\n","        # Extract subimage of nucleus (Not just its values, which is done above)\n","        boolean = np.where(mask==i, 1,False) # Boolean matrix where patch = 1, else 0\n","        patch_values = ypet*boolean\n","        # Extract submatrix with a buffer of 3 pixels to calculate the blurrness\n","        variance_boolean = dilation(boolean, square(7))\n","        variance_values = ypet * variance_boolean\n","        \n","        # Drop pixels without nucleus information ----------------------------------------------------------------\n","        # Initialize conditions on when a column/ row should be dropped\n","        drop_nucleus = False\n","        drop_column = []\n","        drop_column_variance = []\n","        drop_row = []\n","        drop_row_variance = []\n","        \n","        \n","        # Iterate through all columns to find nucleus that is on the border and the columns that only contain mask\n","        for column in range(boolean.shape[1]):\n","            \n","            # drop nucleus if it's on the border \n","            if (((column == 0) | (column == boolean.shape[1]-1)) & (np.any(boolean[:,column])== True)):\n","                drop_nucleus = True\n","                break \n","                \n","            # drop if column has no information about nucleus: first check for broader variance_submatrix (Matrix with a buffer around submatrix to calculate variance). Then smaller submatrix \n","            if np.any(variance_boolean[:,column])== False:\n","                drop_column_variance.append(column) \n","                drop_column.append(column) \n","            elif np.any(boolean[:,column])== False: \n","                drop_column.append(column) \n","        \n","        # Iterate through all columns to find nucleus that is on the border and the columns that only contain mask\n","        for row in range(boolean.shape[0]):\n","            \n","            # drop nucleus if it's on the border \n","            if (((row == 0) | (row == boolean.shape[0]-1)) & (np.any(boolean[row,:])== True)):\n","                drop_nucleus = True\n","                break\n","                \n","            # drop if row has no information about nucleus:  first check for broader variance_submatrix  \n","            if np.any(variance_boolean[row,:])== False:\n","                drop_row.append(row)\n","                drop_row_variance.append(row)\n","            elif np.any(boolean[row,:])== False: \n","                drop_row.append(row)\n","        \n","        # Drop pixels without nucleus information\n","        patch_data = np.delete(patch_values,drop_column,1)  \n","        patch_data = np.delete(patch_data,drop_row,0) \n","        variance_data = np.delete(ypet,drop_column_variance,1)  \n","        variance_data = np.delete(variance_data,drop_row_variance,0) \n","        \n","        '''\n","        # Exploration phase\n","        patch_data_list.append(patch_data)\n","        variance_data_list.append(variance_data)'''\n","        \n","        # Calculate blurness based on laplacian----------------------------------------------------------------\n","        var_lapl = cv2.Laplacian(variance_data, cv2.CV_64F).var()\n","        if var_lapl >= var_threshold: # nucleus is blurry\n","            blured_nucleus = True\n","        else: \n","            blured_nucleus = False\n","        \n","        # Calculate blurness based on skimage----------------------------------------------------------------\n","        blur_ski_nucleus = measure.blur_effect(variance_data)\n","        if blur_ski_nucleus >= blur_threshold:\n","            blur_ski_temp = True\n","        else:\n","            blur_ski_temp = False\n","        \n","        # Feature calculation ----------------------------------------------------------------\n","        \n","        if ((patch_size_ > 10) & (patch_size_ < 50000) & (drop_nucleus== False)): \n","            # extract intensity feature\n","            columnname[iter_i] = \"patch_\" + str(iter_i)    #We should not forgot that there is a -1 here. (when it is here)               \n","            patch_size[iter_i] = patch_size_\n","            blur_lapl[iter_i] = blured_nucleus\n","            blur_ski[iter_i] = blur_ski_temp\n","            sum_intensity[iter_i] = np.sum(np.sum(cur))\n","            mean_intensity[iter_i] = np.nanmean(cur)\n","            median_intensity[iter_i] = np.nanmedian(cur)\n","            \n","            std_intensity[iter_i] = np.nanstd(cur)\n","            var_intensity[iter_i] = np.nanvar(cur)\n","            skew_intesity[iter_i] = scipy.stats.skew(cur)\n","            kurt_intesity[iter_i] = scipy.stats.kurtosis(cur)\n","            iqr_intesity[iter_i] = scipy.stats.iqr(cur)\n","            entropy_intesity[iter_i] = scipy.stats.entropy(cur)\n","            \n","            gabor_features[iter_i] = gabor_feature_extraction(kernels,patch_data) # List of two arrays, first nb of counts in histogram, second: bin number\n","            temp_lbp = feature_binary_pattern(patch_data)\n","            lbp_features[iter_i]  = temp_lbp\n","            lbp_count = len(temp_lbp)\n","            \n","            perimeter[iter_i] = props[i-1].perimeter\n","            feret_diameter_max[iter_i] = props[i-1].feret_diameter_max\n","            area_test[iter_i] = props[i-1].area\n","            axis_major[iter_i] = props[i-1].major_axis_length\n","            axis_minor[iter_i] = props[i-1].minor_axis_length\n","            solidity[iter_i] = props[i-1].solidity\n","            \n","            iter_i +=1\n","    \n","    # Drop empty rows: some patches values were not calculated because their size is too small/big \n","    if iter_i != range_s: # Some patches were not considered -> we have to drop those rows\n","        mean_intensity = mean_intensity[:iter_i]\n","        columnname = columnname[:iter_i]\n","        blur_lapl = blur_lapl[:iter_i]\n","        blur_ski = blur_ski[:iter_i]\n","        patch_size = patch_size[:iter_i]\n","        sum_intensity = sum_intensity[:iter_i]\n","        median_intensity = median_intensity[:iter_i]\n","        imgs = imgs[:iter_i]\n","        std_intensity = std_intensity[:iter_i] \n","        var_intensity = var_intensity[:iter_i] \n","        skew_intesity = skew_intesity[:iter_i] \n","        kurt_intesity = kurt_intesity[:iter_i] \n","        iqr_intesity = iqr_intesity[:iter_i]\n","        entropy_intesity = entropy_intesity[:iter_i] \n","        gabor_features = gabor_features[:iter_i] \n","        lbp_features = lbp_features[:iter_i] \n","        \n","        perimeter = perimeter[:iter_i]\n","        feret_diameter_max = feret_diameter_max[:iter_i]\n","        area_test = area_test[:iter_i]\n","        axis_major = axis_major[:iter_i]\n","        axis_minor = axis_minor[:iter_i]\n","        solidity = solidity[:iter_i]\n","        \n","    ypet_intensity = pd.DataFrame(index=columnname)\n","    ypet_intensity['img'] = imgs\n","    ypet_intensity['fld'] = ypet_intensity['img']+1 #To remember the flow from which (img+1)\n","    ypet_intensity['TF_name'] = TF_name\n","    ypet_intensity['blur_lapl'] = blur_lapl\n","    ypet_intensity['blur_ski'] = blur_ski\n","    ypet_intensity['patch_size'] = patch_size\n","    ypet_intensity['mean_intensity'] = mean_intensity\n","    ypet_intensity['sum_intensity'] = sum_intensity\n","    ypet_intensity['median_intensity'] = median_intensity\n","    \n","    ypet_intensity['standard_deviation'] = std_intensity \n","    ypet_intensity['variance'] = var_intensity\n","    ypet_intensity['skewness'] = skew_intesity\n","    ypet_intensity['kurtosis'] = kurt_intesity\n","    ypet_intensity['interquartile_range ']= iqr_intesity\n","    ypet_intensity['entropy'] = entropy_intesity\n","    ypet_intensity['Perimeter'] = perimeter \n","    ypet_intensity['area_Test'] = area_test\n","    ypet_intensity['axis_major_length'] = axis_major\n","    ypet_intensity['feret_diameter_max'] = feret_diameter_max\n","    ypet_intensity['axis_minor_length'] = axis_minor\n","    ypet_intensity['solidity'] = solidity\n","    \n","    if imgs == []:\n","        print('All nucleis have been droppped. In order to extract features you need nucleus that are not by the border and not blurry.')\n","    else: \n","        gabor_features_tot = np.vstack(gabor_features)\n","        lbp_features_tot = np.vstack(lbp_features)\n","\n","        for filter_bank in range (len(kernels)):\n","            name = 'gabro_'+ str(filter_bank)\n","            ypet_intensity[name] = gabor_features_tot[:,filter_bank]\n","\n","\n","        for lbp_features_count in range (lbp_features_tot.shape[1]):\n","            name = 'lbp_' + str(lbp_features_count)\n","            ypet_intensity[name] = lbp_features_tot[:,lbp_features_count]\n","    ypet_intensity_glob = ypet_intensity_glob.append(ypet_intensity)  #pd.concat([ypet_intensity_glob,ypet_intensity])\n","    print('size of ypet_intisity glob +1 df (=',j+1,')! (usually over 12')\n","            \n","\n","  path = '/content/gdrive/MyDrive/ML_2_transcripted_cherry/Features/TF1_'+let+str(k+1)+'.csv'\n","  with open(path, 'w', encoding = 'utf-8-sig') as f:\n","    ypet_intensity_glob.to_csv(f)\n","\n","    print('hey, it is saved!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":670},"id":"FG0hRHnCNnkS","outputId":"256e2493-8181-4203-f263-12112146421d","executionInfo":{"status":"error","timestamp":1671115424770,"user_tz":-60,"elapsed":8468962,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}}},"id":"FG0hRHnCNnkS","execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 25.3M/25.3M [00:03<00:00, 7.76MB/s]\n","100%|██████████| 3.54k/3.54k [00:00<00:00, 1.51MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["hey, it is saved!\n","hey, it is saved!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n","  return _methods._mean(a, axis=axis, dtype=dtype,\n","/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n","WARNING:cellpose.dynamics:WARNING: no mask pixels found\n"]},{"output_type":"stream","name":"stdout","text":["All nucleis have been droppped. In order to extract features you need nucleus that are not by the border and not blurry.\n","All nucleis have been droppped. In order to extract features you need nucleus that are not by the border and not blurry.\n","All nucleis have been droppped. In order to extract features you need nucleus that are not by the border and not blurry.\n","hey, it is saved!\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-78be51166e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mgabor_features_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgabor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mlbp_features_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbp_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilter_bank\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 8 and the array at index 37 has size 4"]}]},{"cell_type":"code","source":["print('/content/gdrive/MyDrive/ML_2_transcripted_cherry/TF1/A - 1(fld 1 wv TexasRed - TexasRed).tif')\n","print(Image_Directory+end_of_file_name(let,k+1,1,cherry_condition))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aiP9PJKsUy-1","executionInfo":{"status":"ok","timestamp":1671032990999,"user_tz":-60,"elapsed":214,"user":{"displayName":"Alexis Janin","userId":"06183722824926644012"}},"outputId":"8379e270-29e6-49cf-bbbc-f424c6fac44b"},"id":"aiP9PJKsUy-1","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/ML_2_transcripted_cherry/TF1/A - 1(fld 1 wv TexasRed - TexasRed).tif\n","/content/drive/MyDrive/ML_2_transcripted_cherry/TF1/A - 1(fld 1 wv TexasRed - TexasRed).tif\n"]}]},{"cell_type":"markdown","id":"a5b696c2-590f-46d6-8da2-fb3fd76a2629","metadata":{"id":"a5b696c2-590f-46d6-8da2-fb3fd76a2629"},"source":["### Add column with circularity"]},{"cell_type":"markdown","id":"b4537893-fc17-4846-a95c-63af98ea3fcf","metadata":{"id":"b4537893-fc17-4846-a95c-63af98ea3fcf"},"source":["Formula for circularity: 4*pi*area/(perimeter^2)\n","Zero would mean that it is a circle. Everything else is between zero and one."]},{"cell_type":"code","execution_count":null,"id":"ce7a1e9e-5bfc-4cdc-ad29-7f61910cea95","metadata":{"id":"ce7a1e9e-5bfc-4cdc-ad29-7f61910cea95"},"outputs":[],"source":["ypet_intensity['Circularity'] = (4*np.pi*ypet_intensity['patch_size'])/(ypet_intensity['Perimeter']**2)"]},{"cell_type":"code","execution_count":null,"id":"cb37dd8d-1aa0-428f-80d4-51c7cbe520a9","metadata":{"id":"cb37dd8d-1aa0-428f-80d4-51c7cbe520a9","outputId":"bad4a854-fccd-49cd-b446-4aa9ac7be855"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img</th>\n","      <th>TF_name</th>\n","      <th>blur_lapl</th>\n","      <th>blur_ski</th>\n","      <th>patch_size</th>\n","      <th>mean_intensity</th>\n","      <th>sum_intensity</th>\n","      <th>median_intensity</th>\n","      <th>standard_deviation</th>\n","      <th>variance</th>\n","      <th>...</th>\n","      <th>gabro_15</th>\n","      <th>lbp_0</th>\n","      <th>lbp_1</th>\n","      <th>lbp_2</th>\n","      <th>lbp_3</th>\n","      <th>lbp_4</th>\n","      <th>lbp_5</th>\n","      <th>lbp_6</th>\n","      <th>lbp_7</th>\n","      <th>Circularity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>patch_0</th>\n","      <td>0</td>\n","      <td>A - 1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>983</td>\n","      <td>4423.655137</td>\n","      <td>4348453</td>\n","      <td>2839.0</td>\n","      <td>3111.904859</td>\n","      <td>9.683952e+06</td>\n","      <td>...</td>\n","      <td>0.004934</td>\n","      <td>0.136302</td>\n","      <td>0.145749</td>\n","      <td>0.110661</td>\n","      <td>0.130904</td>\n","      <td>0.170040</td>\n","      <td>0.120108</td>\n","      <td>0.072874</td>\n","      <td>0.113360</td>\n","      <td>0.885280</td>\n","    </tr>\n","    <tr>\n","      <th>patch_1</th>\n","      <td>0</td>\n","      <td>A - 1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>815</td>\n","      <td>6564.204908</td>\n","      <td>5349827</td>\n","      <td>7561.0</td>\n","      <td>2752.081685</td>\n","      <td>7.573954e+06</td>\n","      <td>...</td>\n","      <td>0.006048</td>\n","      <td>0.086257</td>\n","      <td>0.096491</td>\n","      <td>0.102339</td>\n","      <td>0.163743</td>\n","      <td>0.255848</td>\n","      <td>0.128655</td>\n","      <td>0.076023</td>\n","      <td>0.090643</td>\n","      <td>0.872776</td>\n","    </tr>\n","    <tr>\n","      <th>patch_2</th>\n","      <td>0</td>\n","      <td>A - 1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>499</td>\n","      <td>9664.827655</td>\n","      <td>4822749</td>\n","      <td>9789.0</td>\n","      <td>1686.611866</td>\n","      <td>2.844660e+06</td>\n","      <td>...</td>\n","      <td>0.005859</td>\n","      <td>0.089862</td>\n","      <td>0.099078</td>\n","      <td>0.094470</td>\n","      <td>0.214286</td>\n","      <td>0.188940</td>\n","      <td>0.172811</td>\n","      <td>0.076037</td>\n","      <td>0.064516</td>\n","      <td>0.879739</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 45 columns</p>\n","</div>"],"text/plain":["         img TF_name  blur_lapl  blur_ski  patch_size  mean_intensity  \\\n","patch_0    0   A - 1      False     False         983     4423.655137   \n","patch_1    0   A - 1      False     False         815     6564.204908   \n","patch_2    0   A - 1      False     False         499     9664.827655   \n","\n","         sum_intensity  median_intensity  standard_deviation      variance  \\\n","patch_0        4348453            2839.0         3111.904859  9.683952e+06   \n","patch_1        5349827            7561.0         2752.081685  7.573954e+06   \n","patch_2        4822749            9789.0         1686.611866  2.844660e+06   \n","\n","         ...  gabro_15     lbp_0     lbp_1     lbp_2     lbp_3     lbp_4  \\\n","patch_0  ...  0.004934  0.136302  0.145749  0.110661  0.130904  0.170040   \n","patch_1  ...  0.006048  0.086257  0.096491  0.102339  0.163743  0.255848   \n","patch_2  ...  0.005859  0.089862  0.099078  0.094470  0.214286  0.188940   \n","\n","            lbp_5     lbp_6     lbp_7  Circularity  \n","patch_0  0.120108  0.072874  0.113360     0.885280  \n","patch_1  0.128655  0.076023  0.090643     0.872776  \n","patch_2  0.172811  0.076037  0.064516     0.879739  \n","\n","[3 rows x 45 columns]"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["ypet_intensity.head()"]}],"metadata":{"colab":{"provenance":[{"file_id":"158pHXq8dG2em_g3xFihk0nOTNy6ecxOY","timestamp":1670264238282}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}