{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf09a9e-e4aa-48b7-945a-1d3656166278",
   "metadata": {},
   "source": [
    "# Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc1fb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import ndimage as ndi\n",
    "import seaborn as sns\n",
    "import re\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "import sklearn\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.linear_model import RidgeCV, LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# https://stackoverflow.com/questions/19970764/making-feature-vector-from-gabor-filters-for-classification\n",
    "# https://stackoverflow.com/questions/20608458/gabor-feature-extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2e5054a5-2a1d-416e-9036-e8c1c0c9efc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patch</th>\n",
       "      <th>img</th>\n",
       "      <th>TF_name</th>\n",
       "      <th>blur_lapl</th>\n",
       "      <th>blur_ski</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>sum_intensity</th>\n",
       "      <th>median_intensity</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>...</th>\n",
       "      <th>gabro_15</th>\n",
       "      <th>lbp_0</th>\n",
       "      <th>lbp_1</th>\n",
       "      <th>lbp_2</th>\n",
       "      <th>lbp_3</th>\n",
       "      <th>lbp_4</th>\n",
       "      <th>lbp_5</th>\n",
       "      <th>lbp_6</th>\n",
       "      <th>lbp_7</th>\n",
       "      <th>Circularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patch_6</td>\n",
       "      <td>1</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>557</td>\n",
       "      <td>790.666068</td>\n",
       "      <td>440401</td>\n",
       "      <td>790.0</td>\n",
       "      <td>56.209692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.259459</td>\n",
       "      <td>0.167568</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.102703</td>\n",
       "      <td>0.064865</td>\n",
       "      <td>0.083784</td>\n",
       "      <td>0.089189</td>\n",
       "      <td>0.137838</td>\n",
       "      <td>0.726082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patch_7</td>\n",
       "      <td>1</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>739</td>\n",
       "      <td>1042.802436</td>\n",
       "      <td>770631</td>\n",
       "      <td>926.0</td>\n",
       "      <td>274.833903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.208835</td>\n",
       "      <td>0.178715</td>\n",
       "      <td>0.102410</td>\n",
       "      <td>0.128514</td>\n",
       "      <td>0.076305</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.076305</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.794946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patch_8</td>\n",
       "      <td>1</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>680</td>\n",
       "      <td>841.535294</td>\n",
       "      <td>572244</td>\n",
       "      <td>831.0</td>\n",
       "      <td>89.429541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064338</td>\n",
       "      <td>0.247140</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>0.091533</td>\n",
       "      <td>0.112128</td>\n",
       "      <td>0.089245</td>\n",
       "      <td>0.082380</td>\n",
       "      <td>0.064073</td>\n",
       "      <td>0.135011</td>\n",
       "      <td>0.853092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patch_9</td>\n",
       "      <td>1</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1234</td>\n",
       "      <td>870.455429</td>\n",
       "      <td>1074142</td>\n",
       "      <td>845.0</td>\n",
       "      <td>117.994204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004808</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.201220</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.091463</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.069512</td>\n",
       "      <td>0.159756</td>\n",
       "      <td>0.812795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patch_11</td>\n",
       "      <td>1</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1106</td>\n",
       "      <td>828.970163</td>\n",
       "      <td>916841</td>\n",
       "      <td>829.0</td>\n",
       "      <td>56.703426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.234890</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.081044</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.086538</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.177198</td>\n",
       "      <td>0.880464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5496</th>\n",
       "      <td>patch_505</td>\n",
       "      <td>12</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1298</td>\n",
       "      <td>828.140216</td>\n",
       "      <td>1074926</td>\n",
       "      <td>819.5</td>\n",
       "      <td>76.862345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>0.234524</td>\n",
       "      <td>0.176190</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.044048</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.080952</td>\n",
       "      <td>0.186905</td>\n",
       "      <td>0.658896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>patch_506</td>\n",
       "      <td>12</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>821</td>\n",
       "      <td>2108.556638</td>\n",
       "      <td>1731125</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>157.649052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.221612</td>\n",
       "      <td>0.148352</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.104396</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.089744</td>\n",
       "      <td>0.137363</td>\n",
       "      <td>0.908437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5498</th>\n",
       "      <td>patch_508</td>\n",
       "      <td>12</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1372</td>\n",
       "      <td>790.250000</td>\n",
       "      <td>1084223</td>\n",
       "      <td>757.0</td>\n",
       "      <td>130.311276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.219163</td>\n",
       "      <td>0.188326</td>\n",
       "      <td>0.105727</td>\n",
       "      <td>0.078194</td>\n",
       "      <td>0.075991</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.160793</td>\n",
       "      <td>0.596698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5499</th>\n",
       "      <td>patch_509</td>\n",
       "      <td>12</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1088</td>\n",
       "      <td>881.883272</td>\n",
       "      <td>959489</td>\n",
       "      <td>867.0</td>\n",
       "      <td>105.353520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>0.194879</td>\n",
       "      <td>0.089616</td>\n",
       "      <td>0.072546</td>\n",
       "      <td>0.049787</td>\n",
       "      <td>0.079659</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.173542</td>\n",
       "      <td>0.889439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>patch_510</td>\n",
       "      <td>12</td>\n",
       "      <td>C - 7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>965</td>\n",
       "      <td>793.436269</td>\n",
       "      <td>765666</td>\n",
       "      <td>792.0</td>\n",
       "      <td>56.694156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.236246</td>\n",
       "      <td>0.169903</td>\n",
       "      <td>0.114887</td>\n",
       "      <td>0.092233</td>\n",
       "      <td>0.066343</td>\n",
       "      <td>0.080906</td>\n",
       "      <td>0.085761</td>\n",
       "      <td>0.153722</td>\n",
       "      <td>0.878375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5501 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          patch  img TF_name  blur_lapl  blur_ski  patch_size  mean_intensity  \\\n",
       "0       patch_6    1   C - 7      False     False         557      790.666068   \n",
       "1       patch_7    1   C - 7      False     False         739     1042.802436   \n",
       "2       patch_8    1   C - 7      False     False         680      841.535294   \n",
       "3       patch_9    1   C - 7      False     False        1234      870.455429   \n",
       "4      patch_11    1   C - 7      False     False        1106      828.970163   \n",
       "...         ...  ...     ...        ...       ...         ...             ...   \n",
       "5496  patch_505   12   C - 7      False     False        1298      828.140216   \n",
       "5497  patch_506   12   C - 7      False     False         821     2108.556638   \n",
       "5498  patch_508   12   C - 7      False     False        1372      790.250000   \n",
       "5499  patch_509   12   C - 7      False     False        1088      881.883272   \n",
       "5500  patch_510   12   C - 7      False     False         965      793.436269   \n",
       "\n",
       "      sum_intensity  median_intensity  standard_deviation  ...  gabro_15  \\\n",
       "0            440401             790.0           56.209692  ...  0.006944   \n",
       "1            770631             926.0          274.833903  ...  0.046875   \n",
       "2            572244             831.0           89.429541  ...  0.064338   \n",
       "3           1074142             845.0          117.994204  ...  0.004808   \n",
       "4            916841             829.0           56.703426  ...  0.019817   \n",
       "...             ...               ...                 ...  ...       ...   \n",
       "5496        1074926             819.5           76.862345  ...  0.023585   \n",
       "5497        1731125            2109.0          157.649052  ...  0.007353   \n",
       "5498        1084223             757.0          130.311276  ...  0.037500   \n",
       "5499         959489             867.0          105.353520  ...  0.034226   \n",
       "5500         765666             792.0           56.694156  ...  0.035714   \n",
       "\n",
       "         lbp_0     lbp_1     lbp_2     lbp_3     lbp_4     lbp_5     lbp_6  \\\n",
       "0     0.259459  0.167568  0.094595  0.102703  0.064865  0.083784  0.089189   \n",
       "1     0.208835  0.178715  0.102410  0.128514  0.076305  0.078313  0.076305   \n",
       "2     0.247140  0.178490  0.091533  0.112128  0.089245  0.082380  0.064073   \n",
       "3     0.200000  0.201220  0.097561  0.100000  0.091463  0.080488  0.069512   \n",
       "4     0.234890  0.192308  0.093407  0.081044  0.057692  0.086538  0.076923   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5496  0.234524  0.176190  0.102381  0.100000  0.044048  0.075000  0.080952   \n",
       "5497  0.221612  0.148352  0.120879  0.104396  0.087912  0.089744  0.089744   \n",
       "5498  0.219163  0.188326  0.105727  0.078194  0.075991  0.085903  0.085903   \n",
       "5499  0.243243  0.194879  0.089616  0.072546  0.049787  0.079659  0.096728   \n",
       "5500  0.236246  0.169903  0.114887  0.092233  0.066343  0.080906  0.085761   \n",
       "\n",
       "         lbp_7  Circularity  \n",
       "0     0.137838     0.726082  \n",
       "1     0.150602     0.794946  \n",
       "2     0.135011     0.853092  \n",
       "3     0.159756     0.812795  \n",
       "4     0.177198     0.880464  \n",
       "...        ...          ...  \n",
       "5496  0.186905     0.658896  \n",
       "5497  0.137363     0.908437  \n",
       "5498  0.160793     0.596698  \n",
       "5499  0.173542     0.889439  \n",
       "5500  0.153722     0.878375  \n",
       "\n",
       "[5501 rows x 49 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF = 'C7'\n",
    "df = pd.read_csv ('../Features/TF1_'+TF+'.csv',index_col = 0)\n",
    "ypet_intensity = df.copy()\n",
    "ypet_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85bfb6-e70e-41dd-9f01-96e86b9c828c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c25bf8-0eef-4e3c-ac41-fc8ce81af9a5",
   "metadata": {},
   "source": [
    "## Parameters to adapt for the data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23b9310f-92f8-4e98-b6fe-e80e84154a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters to adapt for analyzation:\n",
    "#outlier removal\n",
    "outlier = True              #If outliers in general should be removed True, if not False\n",
    "interquantile = True        #if outliers should be removed by defining a range with the interquantile: True; to remove outliers just when they're exceeding a certain quantile: False\n",
    "quantile_keep = 0.95        #to change if interquantile = False; else ignore\n",
    "outlier_columns = ['mean_intensity'] #choose columns of which the outliers should be removed. to choose all the columns: list(ypet_intensity_processed)[6:]\n",
    "outlier_range = 1.5         #if interquantile = True defined this value to define the range. Gets multiplicated with interquantile. Else ignore\n",
    "#Normalization\n",
    "normalization = True\n",
    "columns_to_be_normalized =  ['mean_intensity','median_intensity','sum_intensity'] #list(ypet_intensity_processed)[6:]  #if all columns should be normalized\n",
    "                            #take logs to reduce skewness\n",
    "take_log = False             #want to take the log of certain columns\n",
    "columns_log = ['mean_intensity'] #needs pre-analyzation of columns if log is needed. With a histogram it can be seen if the distribution is skewed. \n",
    "ypet_intensity_processed = ypet_intensity.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba66c31-7080-43e6-bab1-d7318e5a3861",
   "metadata": {},
   "source": [
    "## Outlier removal in columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f58461b-0c8a-4543-960a-31365bdd98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(without_outliers, **kwargs):\n",
    "    #define input parameters\n",
    "    outlier_range =   kwargs['outlier_range']\n",
    "    outlier_columns = kwargs['outlier_columns'] \n",
    "    interquantile =   kwargs['interquantile']\n",
    "    quantile_keep =   kwargs['interquantile']\n",
    "    # first choose which method for outlier removal wants to be used. Use a for loop to iterate over the defined columns of the dataframe.\n",
    "    if interquantile == True:\n",
    "        for col in outlier_columns:\n",
    "            # defined the interquantile range and then the upper and lower limit of the choosen column\n",
    "            median = without_outliers[col].median()\n",
    "            q_75 = without_outliers[col].quantile(q = 0.75)\n",
    "            q_25 = without_outliers[col].quantile(q = 0.25)\n",
    "            interquantile = q_75 - q_25                              \n",
    "            upper_bound = median + (interquantile * outlier_range)\n",
    "            lower_bound = median - (interquantile * outlier_range)\n",
    "\n",
    "            # Create a boolean mask that is True for rows with a value less than or equal to the upper limit and higher or equal to the lower limit\n",
    "            mask = (without_outliers[col] <= upper_bound) & (without_outliers[col] >= lower_bound)\n",
    "            # Use the mask to filter the dataframe\n",
    "            without_outliers = without_outliers[mask]\n",
    "    else: \n",
    "        for col in columns_outliers:\n",
    "            #define the limit up to which the values are kept\n",
    "            quantile_limit = without_outliers[col].quantile(q = quantile_keep)\n",
    "            #define a boolean mask that is True for rows that are in the defined limit\n",
    "            mask = without_outliers[col] <= quantile_limit\n",
    "            #use the mask to filter the dataframe\n",
    "            without_outliers = without_outliers[mask]\n",
    "        \n",
    "    return without_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "693cc466-5487-490c-9a5f-d9e2b5b8e88b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#apply the function for outlier removal\n",
    "if outlier == True:\n",
    "    #group by the TF and just cut the outliers for one TF\n",
    "    without_outliers = ypet_intensity_processed.groupby('TF_name',as_index=False).apply(outlier_removal, outlier_range=outlier_range, outlier_columns=outlier_columns, interquantile = interquantile, quantile_keep=quantile_keep).reset_index()\n",
    "    #change index so dataframe is as before\n",
    "    without_outliers = without_outliers.drop(['level_0'],axis=1)\n",
    "    without_outliers = without_outliers.set_index('level_1')\n",
    "    without_outliers.index.name = None\n",
    "    #save it under a new dataframe\n",
    "    ypet_intensity_processed = without_outliers.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be2620-d799-4f9c-bc39-5d697b17e8cb",
   "metadata": {},
   "source": [
    "## Take logarithm of certain columns to get rid of the skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bacdc39-0fc4-44b5-8353-683b1c4e4751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take logs of certain columns that are skewed\n",
    "if take_log == True:\n",
    "    TF_grouped = ypet_intensity_processed.groupby('TF_name')\n",
    "    log_rows = TF_grouped[columns_log].transform(lambda x: np.log(x))\n",
    "    ypet_intensity_processed[columns_log] = log_rows "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf42e31-7543-4217-9293-de18eb9b207a",
   "metadata": {},
   "source": [
    "## Normalization of columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d1b4d9eb-d914-4289-8961-e3d15d1c37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of columns of the dataframe\n",
    "if normalization == True:\n",
    "    TF_grouped = ypet_intensity_processed.groupby('TF_name')\n",
    "    Normalized_columns = TF_grouped[columns_to_be_normalized].transform(lambda x: (x - x.mean()) / x.std()) #removed rows_to_be to have all col normalized\n",
    "\n",
    "    # Replace normalized\n",
    "    ypet_intensity_processed[columns_to_be_normalized] = Normalized_columns                         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd15508",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87374b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patch', 'img', 'TF_name', 'blur_lapl', 'blur_ski', 'patch_size', 'mean_intensity', 'sum_intensity', 'median_intensity', 'standard_deviation', 'variance', 'skewness', 'kurtosis', 'interquartile_range ', 'entropy', 'Perimeter', 'area_Test', 'axis_major_length', 'feret_diameter_max', 'axis_minor_length', 'solidity', 'similarity', 'hull area', 'correlation coef', 'gabro_0', 'gabro_1', 'gabro_2', 'gabro_3', 'gabro_4', 'gabro_5', 'gabro_6', 'gabro_7', 'gabro_8', 'gabro_9', 'gabro_10', 'gabro_11', 'gabro_12', 'gabro_13', 'gabro_14', 'gabro_15', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5', 'lbp_6', 'lbp_7', 'Circularity']\n"
     ]
    }
   ],
   "source": [
    "print(list(ypet_intensity_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe1c76",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "## Scatterplots of different parameters compared to each other\n",
    "\n",
    "Scatterplots (if you want with regression line (degree 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc551424",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression cannot contain assignment, perhaps you meant \"==\"? (4292180342.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\alexi\\AppData\\Local\\Temp\\ipykernel_17472\\4292180342.py\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    plt.savefig(\"densities_\"+TF=\".svg\")\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
     ]
    }
   ],
   "source": [
    "mk_size = 0.01 #Choose a small mk_size if a lot of datapoints, so densities are easier to read\n",
    "points_col = 'black'\n",
    "line_col   = 'blue'\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(221)\n",
    "sns.regplot(y=\"patch_size\", x=\"mean_intensity\", data=ypet_intensity_processed,marker = '.',scatter_kws={'s':mk_size}, color = points_col, fit_reg=False)\n",
    "plt.subplot(222)\n",
    "sns.regplot(y=\"patch_size\", x=\"median_intensity\", data=ypet_intensity_processed,marker = '.',scatter_kws={'s':mk_size}, color = points_col, fit_reg=False)\n",
    "plt.subplot(223)\n",
    "sns.regplot(y=\"patch_size\", x=\"sum_intensity\", data=ypet_intensity_processed,marker = '.',scatter_kws={'s':mk_size}, color = points_col, fit_reg=False)\n",
    "plt.subplot(224)\n",
    "sns.regplot(y=\"patch_size\", x=\"correlation coef\", data=ypet_intensity_processed,marker = '.',scatter_kws={'s':mk_size}, color = points_col, fit_reg=False)\n",
    "plt.axvline(np.mean(ypet_intensity_processed['correlation coef']),color = line_col,linewidth = 0.5,label = \"Mean\")\n",
    "plt.legend()\n",
    "plt.suptitle(\"Densities of various measure for TF \"+TF)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"densities_\"+TF=\".svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70de9b1-26c1-44b5-aa4f-34257b8fe69e",
   "metadata": {},
   "source": [
    "## Parameters to define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef7aae-cc98-42fd-9ce4-5fc9a70f68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxdegree = 3                          #To define is the maximum degree of the polynomial that should be tried (maxdegree of 5 takes degree up to 4 into account)\n",
    "x_features = ['mean_intensity','sum_intensity','correlation coef','median_intensity'] #define a list with all the columns that could be interesting for task 1\n",
    "decide_x_features = np.array([2])      #set the list of indexes for the X values used for regression from list defined in test_features\n",
    "decide_y_feature = 'patch_size'        #also other features could be taken into account\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a534b-9934-4abf-b023-754a6307b11f",
   "metadata": {},
   "source": [
    "## Prepare test and train sets and X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85217c8a-5f90-45bb-b8ec-e43b387f03d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define features used with the right format, following x_features and decide_x_features\n",
    "features_used = [x_features[i] for i in decide_x_features]\n",
    "\n",
    "# Split in train and test set\n",
    "df_train, df_test = train_test_split(ypet_intensity_processed, train_size = 0.8, test_size = 0.2, random_state = 10)\n",
    "\n",
    "#define the x and the y for the test and train sets\n",
    "df_train_x = df_train[features_used]\n",
    "df_test_x = df_test[features_used]\n",
    "\n",
    "df_train_y = df_train[[decide_y_feature]]\n",
    "df_test_y = df_test[[decide_y_feature]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eef08b8-1d15-4fbd-89dd-c84547ad7005",
   "metadata": {},
   "source": [
    "## Apply cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb9c9df-7259-4808-b1e3-79720eb6c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model to select\n",
    "cross_validation_ridge_error = np.zeros(maxdegree)\n",
    "cross_validation_lm_error = np.zeros(maxdegree)\n",
    "\n",
    "#see which degree fits data the best for linear regression\n",
    "for d in range(1, maxdegree+1):    #it will create 1,2...maxdregree range vector like this\n",
    "    #polynomial feature expansion of x_train\n",
    "    x_poly_train = PolynomialFeatures(degree=d).fit_transform(df_train_x)\n",
    "    #apply linear regression model and cross-validation for alpha-ridge regression\n",
    "    lr = LinearRegression()\n",
    "    rr = RidgeCV(alphas=[1e-3, 1e-2, 1e-1, 1])\n",
    "    #apply cross validation\n",
    "    cve = cross_validate(lr,x_poly_train,df_train_y,scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "    crr = cross_validate(rr,x_poly_train,df_train_y,scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "    #make array for cross validation with linear model and for ridge regression\n",
    "    cross_validation_lm_error[d-1] = np.mean(np.absolute(cve['test_score']))\n",
    "    cross_validation_ridge_error[d-1] = np.mean(np.absolute(crr['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2c8a8e-1fe4-4c26-8255-fdf1538593f3",
   "metadata": {},
   "source": [
    "## Choose best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3b7444-d516-41ce-a05d-3885e3c6fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_min_lm = np.argmin(cross_validation_lm_error)\n",
    "index_min_ridge = np.argmin(cross_validation_ridge_error)\n",
    "\n",
    "poly_lm_test = PolynomialFeatures(degree=index_min_lm+1)\n",
    "x_poly_test_lm = poly_lm_test.fit_transform(df_test_x)\n",
    "poly_lm_train = PolynomialFeatures(degree=index_min_lm+1)\n",
    "x_poly_train_lm = poly_lm_train.fit_transform(df_train_x)\n",
    "\n",
    "x_poly_train_df_lm = pd.DataFrame(x_poly_train_lm)\n",
    "x_poly_test_df_lm = pd.DataFrame(x_poly_test_lm)\n",
    "\n",
    "poly_ridge_test = PolynomialFeatures(degree=index_min_ridge+1)\n",
    "x_poly_test_ridge = poly_ridge_test.fit_transform(df_test_x)\n",
    "poly_ridge_train = PolynomialFeatures(degree=index_min_ridge+1)\n",
    "x_poly_train_ridge = poly_ridge_train.fit_transform(df_train_x)\n",
    "\n",
    "x_poly_train_df_ridge = pd.DataFrame(x_poly_train_ridge)\n",
    "x_poly_test_df_ridge = pd.DataFrame(x_poly_test_ridge)\n",
    "\n",
    "#make linear model\n",
    "model_lm = LinearRegression().fit(x_poly_train_df_lm, df_train_y)\n",
    "model_ridge = RidgeCV(alphas=[1e-4,1e-3, 1e-2, 1e-1, 1]).fit(x_poly_train_df_ridge, df_train_y)\n",
    "\n",
    "#train error\n",
    "y_train_pred_lm = model_lm.predict(x_poly_train_lm)\n",
    "mse_train_lm = mean_squared_error(df_train_y,y_train_pred_lm)\n",
    "y_train_pred_ridge = model_ridge.predict(x_poly_train_ridge)\n",
    "mse_train_ridge = mean_squared_error(df_train_y,y_train_pred_ridge)\n",
    "\n",
    "#test error\n",
    "y_test_pred_lm = model_lm.predict(x_poly_test_df_lm)\n",
    "mse_test_lm = mean_squared_error(df_test_y,y_test_pred_lm)\n",
    "y_test_pred_ridge = model_ridge.predict(x_poly_test_df_ridge)\n",
    "mse_test_ridge = mean_squared_error(df_test_y,y_test_pred_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0abea-0110-43c2-8c5a-3fb5a9cfaa68",
   "metadata": {},
   "source": [
    "## Visualize the best model and give back the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_sort = pd.DataFrame(df_test_x)\n",
    "df_plot_sort['reg'] =  y_test_pred_lm[:,0]\n",
    "df_plot_sort.sort_values(features_used[0],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb11f6b-33b8-4509-90b1-f4e40bdd0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show predicted points with linear model\n",
    "\n",
    "if (len(features_used)!=1):\n",
    "    warnings.warn(\"WARNING features_used should be of len 1 for this plot\")\n",
    "else:\n",
    "    plt.figure()\n",
    "    plt.plot(df_train_x,df_train_y, 'r.',markersize = 1,label = \"Train set\")\n",
    "    plt.plot(df_plot_sort[features_used[0]],df_plot_sort['reg'],color = 'black',label = \"Regression on test set\")\n",
    "    plt.ylabel(\"Nucleus size\")\n",
    "    plt.xlabel(features_used[0])    #WARNING features_used should be of len 1 for this plot\n",
    "    plt.title(\"Linear model\")\n",
    "    plt.legend()\n",
    "    #plt.yscale(\"log\")\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "''' OLD WAY TO PLOT IT (if need to go back)\n",
    "#show predicted points with linear model\n",
    "plt.plot(df_train_x,df_train_y, 'ro')\n",
    "plt.plot(df_test_x,y_test_pred_lm, 'o',color = 'black')\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ee48f-e627-4aaf-b1bc-fb64ccfb9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show predicted points with linear model\n",
    "df_plot_sort_ridge = pd.DataFrame(df_test_x)\n",
    "df_plot_sort_ridge['reg'] =  y_test_pred_ridge[:,0]\n",
    "df_plot_sort_ridge.sort_values(features_used[0],inplace = True)\n",
    "\n",
    "if (len(features_used)!=1):\n",
    "    warnings.warn(\"WARNING features_used should be of len 1 for this plot\")\n",
    "else:\n",
    "    plt.figure()\n",
    "    plt.plot(df_train_x,df_train_y, 'r.',markersize = 1,label = \"Train set\")\n",
    "    plt.plot(df_plot_sort_ridge[features_used[0]],df_plot_sort_ridge['reg'],color = 'black',label = \"Regression on test set\")\n",
    "    plt.ylabel(\"Nucleus size\")\n",
    "    plt.xlabel(features_used[0])    #WARNING features_used should be of len 1 for this plot\n",
    "    plt.title(\"Ridge regression model\")\n",
    "    plt.legend()\n",
    "    #plt.yscale(\"log\")\n",
    "    #plt.xscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "''' OLD WAY TO PLOT IT (if need to go back)\n",
    "#show predicted points with ridge regression\n",
    "plt.plot(df_train_x,df_train_y, 'ro')\n",
    "plt.plot(df_test_x,y_test_pred_ridge, 'o',color = 'black')\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa463616-f6a8-4356-9851-3b49f5fb5ffc",
   "metadata": {},
   "source": [
    "## Output of the coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097be32-614e-4d88-8be9-cd4bd1718a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if mse_test_ridge >= mse_test_lm:\n",
    "    feature_names = poly_lm_test.get_feature_names_out(input_features=features_used)\n",
    "    print('take linear regression')\n",
    "    print('features: ',feature_names)\n",
    "    print('coefficients: ',model_lm.coef_)\n",
    "    print('intercept: ',model_lm.intercept_)\n",
    "    print('R^2-score: ', r2_score(df_train_y,y_train_pred_lm))\n",
    "    \n",
    "\n",
    "else:\n",
    "    feature_names = poly_ridge_test.get_feature_names_out(input_features=features_used)\n",
    "    print('take ridge regression')\n",
    "    print('features: ',feature_names)\n",
    "    print('coefficients: ',model_ridge.coef_)\n",
    "    print('intercept: ',model_ridge.intercept_)\n",
    "    print('alpha: ',model_ridge.alpha_)\n",
    "    print('R^2-score: ', r2_score(df_train_y,y_train_pred_ridge))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "158pHXq8dG2em_g3xFihk0nOTNy6ecxOY",
     "timestamp": 1670264238282
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
